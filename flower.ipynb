{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Defines our base directory and flower classes\n",
    "- Counts and displays the number of images in each class\n",
    "- Helps us understand our dataset distribution\n",
    "- Important for identifying any class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define paths and create necessary directories\n",
    "base_dir = 'archive/flowers'\n",
    "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "# Print number of images per class\n",
    "for flower_class in classes:\n",
    "    class_path = os.path.join(base_dir, flower_class)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Number of {flower_class} images: {num_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Creates the directory structure for our split datasets\n",
    "- Makes separate folders for train, validation, and test sets\n",
    "- Creates subfolders for each flower class\n",
    "- Ensures clean organization of our data\n",
    "\n",
    "- Splits our data into training (70%), validation (15%), and test (15%) sets\n",
    "- Randomly shuffles images before splitting\n",
    "- Maintains class structure in each split\n",
    "- Physically copies images to their respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create train/validation/test split directories\n",
    "output_base_dir = 'flowers_split'\n",
    "train_dir = os.path.join(output_base_dir, 'train')\n",
    "val_dir = os.path.join(output_base_dir, 'validation')\n",
    "test_dir = os.path.join(output_base_dir, 'test')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        for flower_class in classes:\n",
    "            os.makedirs(os.path.join(dir_path, flower_class))\n",
    "\n",
    "# Cell 4: Split data into train/validation/test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "for flower_class in classes:\n",
    "    src_dir = os.path.join(base_dir, flower_class)\n",
    "    images = os.listdir(src_dir)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    n_images = len(images)\n",
    "    n_train = int(n_images * train_ratio)\n",
    "    n_val = int(n_images * val_ratio)\n",
    "    \n",
    "    # Split images\n",
    "    train_images = images[:n_train]\n",
    "    val_images = images[n_train:n_train + n_val]\n",
    "    test_images = images[n_train + n_val:]\n",
    "    \n",
    "    # Copy images to respective directories\n",
    "    for img in train_images:\n",
    "        src = os.path.join(src_dir, img)\n",
    "        dst = os.path.join(train_dir, flower_class, img)\n",
    "        shutil.copy(src, dst)\n",
    "        \n",
    "    for img in val_images:\n",
    "        src = os.path.join(src_dir, img)\n",
    "        dst = os.path.join(val_dir, flower_class, img)\n",
    "        shutil.copy(src, dst)\n",
    "        \n",
    "    for img in test_images:\n",
    "        src = os.path.join(src_dir, img)\n",
    "        dst = os.path.join(test_dir, flower_class, img)\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Sets up image preprocessing parameters\n",
    "- Standardizes image sizes to 128x128 pixels\n",
    "- Sets batch size to 32 images\n",
    "- Creates data generators that:\n",
    "  - Rescale pixel values to [0,1]\n",
    "  - Load images in batches\n",
    "  - Convert class labels to categorical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Set up data generators\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture explanation:\n",
    "1. First Conv2D layer (32 filters):\n",
    "   - Input layer accepting RGB images (3 channels)\n",
    "   - 3x3 kernel size for feature extraction\n",
    "   - ReLU activation for non-linearity\n",
    "\n",
    "2. Three Conv2D-MaxPooling blocks:\n",
    "   - Increasing filters (32 → 64 → 128)\n",
    "   - MaxPooling reduces spatial dimensions\n",
    "   - Helps extract hierarchical features\n",
    "\n",
    "3. Flatten and Dense layers:\n",
    "   - Converts 2D features to 1D\n",
    "   - 128 neurons in dense layer\n",
    "   - Dropout (0.5) for regularization\n",
    "   - Final layer matches number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Trains the model for 15 epochs\n",
    "- Uses the training generator for batched training\n",
    "- Validates on validation set after each epoch\n",
    "- Stores training history for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Train the model\n",
    "EPOCHS = 15\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Creates two plots:\n",
    "  1. Accuracy over time (training vs validation)\n",
    "  2. Loss over time (training vs validation)\n",
    "- Helps identify:\n",
    "  - Model convergence\n",
    "  - Overfitting\n",
    "  - Training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot training results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Makes predictions on test set\n",
    "- Creates confusion matrix\n",
    "- Generates classification report with:\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1-score\n",
    "  - Support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate the model and create confusion matrix\n",
    "# Get predictions\n",
    "test_steps = test_generator.n // test_generator.batch_size + 1\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes[:len(predicted_classes)]\n",
    "\n",
    "# Create and plot confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "- Calculates ROC curves for each class\n",
    "- Computes AUC (Area Under Curve)\n",
    "- Visualizes model's ability to distinguish between classes\n",
    "- Helps assess classification performance at various thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "n_classes = len(classes)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(\n",
    "        tf.keras.utils.to_categorical(true_classes)[:, i],\n",
    "        predictions[:, i]\n",
    "    )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of {class_labels[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Hyperparameters:\n",
    "\n",
    "1. Image Size (128x128):\n",
    "   - Standardizes input\n",
    "   - Balances detail vs computation\n",
    "   - Memory efficient\n",
    "\n",
    "2. Batch Size (32):\n",
    "   - Affects training stability\n",
    "   - Impacts memory usage\n",
    "   - Influences gradient updates\n",
    "\n",
    "3. Dropout Rate (0.5):\n",
    "   - Prevents overfitting\n",
    "   - Improves generalization\n",
    "   - Standard starting value\n",
    "\n",
    "4. Learning Rate (0.0005):\n",
    "   - Controls weight update size\n",
    "   - Affects training stability\n",
    "   - Chosen for stable convergence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
